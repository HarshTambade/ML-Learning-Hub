"""\nChapter 04: Data Loading and Exploration\nDemonstrates practical techniques for loading data from various sources\nand performing exploratory data analysis (EDA).\n"""\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import skew\n\n# ============================================================================\n# 1. LOADING DATA FROM DIFFERENT SOURCES\n# ============================================================================\n\nprint("=" * 70)\nprint("1. LOADING DATA FROM DIFFERENT SOURCES")\nprint("=" * 70)\n\n# Create sample data for demonstration\nprint("\\n1.1 Creating sample dataset:")\nsample_data = {\n    'ID': range(1, 101),\n    'Age': np.random.randint(20, 80, 100),\n    'Income': np.random.normal(50000, 15000, 100),\n    'Experience': np.random.randint(0, 40, 100),\n    'Department': np.random.choice(['Sales', 'HR', 'IT', 'Finance'], 100),\n    'Satisfaction': np.random.rand(100) * 10\n}\ndf = pd.DataFrame(sample_data)\nprint(f"Dataset shape: {df.shape}")\nprint(f"\\nFirst few rows:\\n{df.head()}")\n\n# ============================================================================\n# 2. INITIAL DATA EXPLORATION\n# ============================================================================\n\nprint("\\n" + "=" * 70)\nprint("2. INITIAL DATA EXPLORATION")\nprint("=" * 70)\n\n# 2.1 Basic info\nprint("\\n2.1 Dataset Info:")\nprint(df.info())\nprint("\\n2.2 Statistical Summary:")\nprint(df.describe())\nprint("\\n2.3 Data Types:")\nprint(df.dtypes)\n\n# ============================================================================\n# 3. MISSING VALUE ANALYSIS\n# ============================================================================\n\nprint("\\n" + "=" * 70)\nprint("3. MISSING VALUE ANALYSIS")\nprint("=" * 70)\n\ndf_with_missing = df.copy()\ndf_with_missing.loc[5:10, 'Income'] = np.nan\ndf_with_missing.loc[15:20, 'Satisfaction'] = np.nan\n\nprint("\\n3.1 Missing Values Count:")\nprint(df_with_missing.isnull().sum())\nprint("\\n3.2 Missing Values Percentage:")\nprint((df_with_missing.isnull().sum() / len(df_with_missing)) * 100)\n\n# ============================================================================\n# 4. DUPLICATE VALUE ANALYSIS\n# ============================================================================\n\nprint("\\n" + "=" * 70)\nprint("4. DUPLICATE VALUE ANALYSIS")\nprint("=" * 70)\n\nprint("\\n4.1 Duplicate Rows: ", df.duplicated().sum())\ndf_no_dups = df.drop_duplicates()\nprint(f"Shape after removing: {df_no_dups.shape}")\n\n# ============================================================================\n# 5. OUTLIER DETECTION (IQR METHOD)\n# ============================================================================\n\nprint("\\n" + "=" * 70)\nprint("5. OUTLIER DETECTION")\nprint("=" * 70)\n\nQ1 = df['Age'].quantile(0.25)\nQ3 = df['Age'].quantile(0.75)\nIQR = Q3 - Q1\nlower = Q1 - 1.5 * IQR\nupper = Q3 + 1.5 * IQR\noutliers = df[(df['Age'] < lower) | (df['Age'] > upper)]\nprint(f"\\nOutliers in Age: {len(outliers)}")\n\n# ============================================================================\n# 6. DATA DISTRIBUTION ANALYSIS\n# ============================================================================\n\nprint("\\n" + "=" * 70)\nprint("6. DATA DISTRIBUTION")\nprint("=" * 70)\n\nprint("\\n6.1 Department Distribution:")\nprint(df['Department'].value_counts())\nprint("\\n6.2 Age Skewness:", f\"{skew(df['Age']):.4f}\")\n\n# ============================================================================\n# 7. CORRELATION ANALYSIS\n# ============================================================================\n\nprint("\\n" + "=" * 70)\nprint("7. CORRELATION ANALYSIS")\nprint("=" * 70)\n\ncorr = df[['Age', 'Income', 'Experience']].corr()\nprint("\\nCorrelation Matrix:")\nprint(corr)\n\nprint("\\n" + "=" * 70)\nprint("Data exploration complete!")\nprint("=" * 70)
